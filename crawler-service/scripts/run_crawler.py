#!/usr/bin/env python3
"""
í¬ë¡¤ëŸ¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
sys.path.append('.')

from crawler.job_crawler import JobCrawler

def main():
    """ê¸°ë³¸ í¬ë¡¤ë§ (ì‹ ê·œë§Œ)"""
    with JobCrawler() as crawler:
        sites = ['wanted', 'saramin', 'jobkorea']
        
        print("ðŸš€ 3ê°œ ì‚¬ì´íŠ¸ í¬ë¡¤ë§ ì‹œìž‘ (ì‹ ê·œë§Œ)...")
        
        total_results = {}
        
        for site in sites:
            print(f"\nðŸ“ {site.upper()} í¬ë¡¤ë§ ì¤‘...")
            try:
                result = crawler.crawl_site(site, full_crawl=False)
                result.print_summary()
                total_results[site] = result
            except Exception as e:
                print(f"âŒ {site} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ ìš”ì•½
        print("\n" + "="*50)
        print("ðŸŽ¯ ì „ì²´ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½:")
        total_new = sum(r.new_saved for r in total_results.values())
        total_time = sum(r.execution_time for r in total_results.values())
        
        print(f"   âœ… ì´ ì‹ ê·œ ì €ìž¥: {total_new}ê°œ")
        print(f"   â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")

def full_crawl():
    """ì „ì²´ í¬ë¡¤ë§ (ëª¨ë“  ë°ì´í„°)"""
    with JobCrawler() as crawler:
        sites = ['wanted', 'saramin', 'jobkorea']
        
        print("ðŸš€ 3ê°œ ì‚¬ì´íŠ¸ ì „ì²´ í¬ë¡¤ë§ ì‹œìž‘...")
        print("âš ï¸  ì£¼ì˜: ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤!")
        
        total_results = {}
        
        for site in sites:
            print(f"\nðŸ“ {site.upper()} ì „ì²´ í¬ë¡¤ë§ ì¤‘...")
            try:
                result = crawler.crawl_site(site, full_crawl=True)
                result.print_summary()
                total_results[site] = result
            except Exception as e:
                print(f"âŒ {site} í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
        
        # ì „ì²´ ìš”ì•½
        print("\n" + "="*50)
        print("ðŸŽ¯ ì „ì²´ í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½:")
        total_new = sum(r.new_saved for r in total_results.values())
        total_time = sum(r.execution_time for r in total_results.values())
        
        print(f"   âœ… ì´ ì €ìž¥: {total_new}ê°œ")
        print(f"   â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")

def test_single_site(site_name: str, full: bool = False):
    """ë‹¨ì¼ ì‚¬ì´íŠ¸ í…ŒìŠ¤íŠ¸"""
    with JobCrawler() as crawler:
        crawl_type = "ì „ì²´" if full else "ì‹ ê·œ"
        print(f"ðŸ§ª {site_name} {crawl_type} í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸...")
        result = crawler.crawl_site(site_name, full_crawl=full)
        result.print_summary()

if __name__ == "__main__":
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == 'full':
            full_crawl()
        elif command in ['wanted', 'saramin', 'jobkorea']:
            full = len(sys.argv) > 2 and sys.argv[2] == 'full'
            test_single_site(command, full)
        else:
            print("Usage: python scripts/run_crawler.py [full|wanted|saramin|jobkorea] [full]")
    else:
        main()